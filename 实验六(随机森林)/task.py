import numpy as np
import pandas as pd
from collections import Counter

def entropy(label):
    unique_labels, label_counts = np.unique(label, return_counts=True)
    total_samples = len(label)
    ent = 0

    for count in label_counts:
        probability = count / total_samples
        ent -= probability * np.log2(probability)

    return ent

'''
å…ˆä»ç‰¹å¾é›† ğ´
 ä¸­å…ˆéšæœºé€‰å– ğ‘˜
 ä¸ªç‰¹å¾æ„æˆç‰¹å¾é›† ğ´â€²
 ï¼Œå†ä» ğ´â€²
 ä¸­é€‰å–æœ€ä½³åˆ’åˆ†çš„ç‰¹å¾ã€‚ ğ‘˜
 ä¸€èˆ¬å– ğ‘šğ‘ğ‘¥{ğ‘™ğ‘œğ‘”2ğ‘‘,1}
 ,  ğ‘‘
 æ˜¯ ğ´
 çš„å…ƒç´ çš„ä¸ªæ•°ã€‚ä½ å¯ä½¿ç”¨ç‰¹å¾çš„ä¿¡æ¯å¢ç›Šæ¥å†³å®šæœ€ä½³åˆ’åˆ†çš„ç‰¹å¾ã€‚
ã€è¾“å…¥ã€‘ï¼šæ•°æ®é›†Dã€ç‰¹å¾é›†A
ã€è¾“å‡ºã€‘ï¼šéšæœºç‰¹å¾é›†A'ä¸­æœ€ä½³åˆ’åˆ†çš„ç‰¹å¾ç»´æ•°
'''
def best_split(D, A):
    d = len(A)
    k = max(np.log2(d), 1)
    # éšæœºé€‰å–kä¸ªç‰¹å¾
    A_prime = np.random.choice(list(A), int(k), replace=False)

    def split_by_value(feature, label, value):
        indices = np.where(feature == value)
        split_label = label[indices]

        return split_label

    best_information_gain = 0
    best_dimension = None

    for dimension in A_prime:
        feature_values = D[:, dimension]
        unique_values = np.unique(feature_values)
        information_gain = entropy(
            D[:, -1]
        )  # Initialize with the entropy of the whole dataset

        for value in unique_values:
            split_label = split_by_value(feature_values, D[:, -1], value)
            information_gain -= (len(split_label) / len(D)) * entropy(split_label)

        if information_gain > best_information_gain:
            best_information_gain = information_gain
            best_dimension = dimension

    return best_dimension

# è®°ä¸‹æ‰€æœ‰å±æ€§å¯èƒ½çš„å–å€¼
train_frame = pd.read_csv('train_titanic.csv')
D = np.array(train_frame)
A = set(range(D.shape[1] - 1))
possible_value = {}
for every in A:
    possible_value[every] = np.unique(D[:, every])


# æ ‘ç»“ç‚¹ç±»
class Node:
    def __init__(self, isLeaf=True, label=-1, feature_index=-1):
        self.isLeaf = isLeaf  # isLeafè¡¨ç¤ºè¯¥ç»“ç‚¹æ˜¯å¦æ˜¯å¶ç»“ç‚¹
        self.label = label  # labelè¡¨ç¤ºè¯¥å¶ç»“ç‚¹çš„labelï¼ˆå½“ç»“ç‚¹ä¸ºå¶ç»“ç‚¹æ—¶æœ‰ç”¨ï¼‰
        self.feature_index = feature_index  # feature_indexè¡¨ç¤ºè¯¥åˆ†æ”¯ç»“ç‚¹çš„åˆ’åˆ†ç‰¹å¾çš„åºå·ï¼ˆå½“ç»“ç‚¹ä¸ºåˆ†æ”¯ç»“ç‚¹æ—¶æœ‰ç”¨ï¼‰
        self.children = {}  # childrenè¡¨ç¤ºè¯¥ç»“ç‚¹çš„æ‰€æœ‰å­©å­ç»“ç‚¹ï¼Œdictç±»å‹ï¼Œæ–¹ä¾¿è¿›è¡Œå†³ç­–æ ‘çš„æœç´¢

    def addNode(self, val, node):
        self.children[val] = node  # ä¸ºå½“å‰ç»“ç‚¹å¢åŠ ä¸€ä¸ªåˆ’åˆ†ç‰¹å¾çš„å€¼ä¸ºvalçš„å­©å­ç»“ç‚¹


# å†³ç­–æ ‘ç±»
class DTree:
    def __init__(self):
        self.tree_root = None  # å†³ç­–æ ‘çš„æ ¹ç»“ç‚¹
        self.possible_value = possible_value  # ç”¨äºå­˜å‚¨æ¯ä¸ªç‰¹å¾å¯èƒ½çš„å–å€¼

    """
    TreeGenerateå‡½æ•°ç”¨äºé€’å½’æ„å»ºå†³ç­–æ ‘ï¼Œä¼ªä»£ç å‚ç…§è¯¾ä»¶ä¸­çš„â€œAlgorithm 1 å†³ç­–æ ‘å­¦ä¹ åŸºæœ¬ç®—æ³•â€
     
    """

    def TreeGenerate(self, D, A):
        # ç”Ÿæˆç»“ç‚¹ node
        node = Node()

        # if Dä¸­æ ·æœ¬å…¨å±äºåŒä¸€ç±»åˆ«C then
        #     å°†nodeæ ‡è®°ä¸ºCç±»å¶ç»“ç‚¹å¹¶è¿”å›
        # end if
        if len(np.unique(D[:, -1])) == 1:
            node.isLeaf = True
            node.label = D[0, -1]
            return node

        # if A = Ã˜ OR Dä¸­æ ·æœ¬åœ¨Aä¸Šå–å€¼ç›¸åŒ then
        #     å°†nodeæ ‡è®°å¶ç»“ç‚¹ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸ºDä¸­æ ·æœ¬æ•°æœ€å¤šçš„ç±»å¹¶è¿”å›
        # end if
        tmp = np.array(list(A))
        if len(tmp) == 0 or len(np.unique(D[:, tmp])) == 1:
            node.isLeaf = True
            node.label = Counter(D[:, -1]).most_common(1)[0][0]
            return node

        # ä»Aä¸­é€‰æ‹©æœ€ä¼˜åˆ’åˆ†ç‰¹å¾a_star
        # ï¼ˆé€‰æ‹©ä¿¡æ¯å¢ç›Šæœ€å¤§çš„ç‰¹å¾ï¼Œç”¨åˆ°ä¸Šé¢å®ç°çš„best_splitå‡½æ•°ï¼‰
        a_star = best_split(D, A)

        if a_star is not None:
            for a_star_v in np.unique(D[:, a_star]):
                D_v = D[D[:, a_star] == a_star_v]
                if len(D_v) == 0:
                    node.addNode(
                        a_star_v, Node(True, Counter(D[:, -1]).most_common(1)[0][0])
                    )
                else:
                    node.addNode(
                        a_star_v,
                        self.TreeGenerate(
                            D[D[:, a_star] == a_star_v], A - {a_star}
                        ),  # é€’å½’è°ƒç”¨TreeGenerateå‡½æ•°
                    )

        # def __init__(self, isLeaf=True, label=-1, feature_index=-1) nodeçš„æ„é€ å‡½æ•°ä¸­ï¼ŒisLeafé»˜è®¤ä¸ºTrueï¼Œfeature_indexé»˜è®¤ä¸º-1ã€‚è€Œå‡½æ•°æ‰§è¡Œåˆ°è¿™é‡Œæ—¶ï¼Œnodeçš„å€¼éœ€è¦èµ‹å€¼ä¸ºFalseï¼Œfeature_indexéœ€è¦èµ‹å€¼ä¸ºa_star
            node.isLeaf = False
            node.feature_index = a_star
            return node
        else:
            node.isLeaf = True
            node.label = Counter(D[:, -1]).most_common(1)[0][0]
            return node

    """
    trainå‡½æ•°å¯ä»¥åšä¸€äº›æ•°æ®é¢„å¤„ç†ï¼ˆæ¯”å¦‚Dataframeåˆ°numpyçŸ©é˜µçš„è½¬æ¢ï¼Œæå–å±æ€§é›†ç­‰ï¼‰ï¼Œå¹¶è°ƒç”¨TreeGenerateå‡½æ•°æ¥é€’å½’åœ°ç”Ÿæˆå†³ç­–æ ‘
 
    """

    def train(self, D):
        D = np.array(D)  # å°†Dataframeå¯¹è±¡è½¬æ¢ä¸ºnumpyçŸ©é˜µï¼ˆä¹Ÿå¯ä»¥ä¸è½¬ï¼Œè‡ªè¡Œå†³å®šåšæ³•ï¼‰
        
        A = set(range(D.shape[1] - 1))  # ç‰¹å¾é›†A
        # print(A)

        self.tree_root = self.TreeGenerate(D, A)  # é€’å½’åœ°ç”Ÿæˆå†³ç­–æ ‘ï¼Œå¹¶å°†å†³ç­–æ ‘çš„æ ¹ç»“ç‚¹èµ‹å€¼ç»™self.tree_root
        return

    """
    predict(self, D)ï¼šå¯¹æµ‹è¯•é›†Dè¿›è¡Œé¢„æµ‹ï¼Œè¦æ±‚è¿”å›æ•°æ®é›†Dçš„é¢„æµ‹æ ‡ç­¾ï¼Œå³ä¸€ä¸ª(|D|,1)çŸ©é˜µï¼ˆ|D|è¡Œ1åˆ—ï¼‰ã€‚æµ‹è¯•é›†ä¸­å‡ºç°å†³ç­–æ ‘æ— æ³•åˆ’åˆ†çš„ç‰¹å¾å€¼æ—¶çš„æƒ…å†µæ—¶ï¼Œå¯¹å…¶ä¸å†è¿›è¡Œé¢„æµ‹ï¼Œç›´æ¥ç»™å®šåˆ’åˆ†å¤±è´¥çš„æ ·æœ¬æ ‡ç­¾(ä¾‹å¦‚-1)ã€‚
    """

    def predict(self, D):
        D = np.array(D)  # å°†Dataframeå¯¹è±¡è½¬æ¢ä¸ºnumpyçŸ©é˜µï¼ˆä¹Ÿå¯ä»¥ä¸è½¬ï¼Œè‡ªè¡Œå†³å®šåšæ³•ï¼‰
        # å¯¹äºDä¸­çš„æ¯ä¸€è¡Œæ•°æ®dï¼Œä»å½“å‰ç»“ç‚¹x=self.tree_rootå¼€å§‹ï¼Œå½“å½“å‰ç»“ç‚¹xä¸ºåˆ†æ”¯ç»“ç‚¹æ—¶ï¼Œ
        # åˆ™æœç´¢xçš„åˆ’åˆ†ç‰¹å¾ä¸ºè¯¥è¡Œæ•°æ®ç›¸åº”çš„ç‰¹å¾å€¼çš„å­©å­ç»“ç‚¹ï¼ˆå³x=x.children[d[x.index]]ï¼‰ï¼Œä¸æ–­é‡å¤ï¼Œ
        # ç›´è‡³æœç´¢åˆ°å¶ç»“ç‚¹ï¼Œè¯¥å¶ç»“ç‚¹çš„æ ‡ç­¾å°±æ˜¯æ•°æ®dçš„é¢„æµ‹æ ‡ç­¾
        label = []
        for d in D:
            x = self.tree_root
            succeed = True
            while not x.isLeaf:
                # print("x.feature_index:", x.feature_index)
                if d[x.feature_index] not in x.children:
                    succeed = False
                    break
                x = x.children[d[x.feature_index]]
            # print(x.label)
            if succeed:
                label.append(x.label)
            else:
                # å¯¹å…¶ä¸å†è¿›è¡Œé¢„æµ‹ï¼Œç›´æ¥ç»™å®šåˆ’åˆ†å¤±è´¥çš„æ ·æœ¬æ ‡ç­¾ä¸º-1
                label.append(-1)
        return label
    
# Bootstrapé‡‡æ ·
# ç”Ÿæˆ10ä¸ªå†³ç­–æ ‘
s = 0
cur = 0
while cur < 10:
    n = 1000
    tree = [DTree()] * n
    for i in range(n):
        D = np.array(train_frame)
        D = D[np.random.choice(D.shape[0], D.shape[0], replace=True)]
        D = pd.DataFrame(D)
        tree[i].train(D)

    # æµ‹è¯•
    test_frame = pd.read_csv('test_titanic.csv')
    result = []
    for t in tree:
        result.append(t.predict(test_frame))

    # ç›¸å¯¹å¤šæ•°æŠ•ç¥¨
    result = np.array(result)
    res = []
    for i in range(len(result[0])):
        res.append(Counter(result[:, i]).most_common(1)[0][0])


    accuracy = np.sum(res == test_frame['Survived']) / len(test_frame)
    s += accuracy
    print("ç¬¬", cur + 1, "æ¬¡å‡†ç¡®ç‡ï¼š", accuracy)
    cur += 1
s /= cur
print("å¹³å‡å‡†ç¡®ç‡ï¼š", s)