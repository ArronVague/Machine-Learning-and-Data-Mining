{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e59a56ee",
   "metadata": {},
   "source": [
    "**<font color = black size=6>实验十二：神经网络</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f100c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "import os  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c03386",
   "metadata": {},
   "source": [
    "本实验使用Pytorch框架搭建神经网络，其他类似的框架还有TensorFlow。若同学对TensorFlow框架更为熟悉，可使用TensorFlow完成本次实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebaf0fe",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第一部分:PyTorch介绍</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a394db6",
   "metadata": {},
   "source": [
    "这里介绍一小部分PyTorch常用的库和函数，更多需求可参阅[PyTorch官方教程](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)以及[PyTorch官方文档](https://pytorch.org/docs/stable/index.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae149b",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(torch.__version__) # 输出当前版本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392780bb",
   "metadata": {},
   "source": [
    "**<font color = green size=3>1.Tensor</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904623e4",
   "metadata": {},
   "source": [
    "Tensor与NumPy中的ndarray很相似，但Tensor可以利用GPU来加速计算（本次实验中暂不涉及这部分内容）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23642996",
   "metadata": {},
   "source": [
    "1.1. Tensor的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38cdf3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 4.2969, 0.0000],\n",
      "        [0.0000, 0.0000, 4.5977]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0.7687, 0.8341, 0.2797, 0.1409],\n",
      "        [0.4442, 0.4342, 0.5008, 0.2835],\n",
      "        [0.7328, 0.0959, 0.2500, 0.0992]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个未初始化的Tensor\n",
    "x = torch.empty(2, 3)\n",
    "print(x)\n",
    "\n",
    "# 从一个列表创建Tensor\n",
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# 创建一个随机Tensor\n",
    "x = torch.rand([3, 4])\n",
    "print(x)\n",
    "\n",
    "# 创建一个全零Tensor\n",
    "x = torch.zeros([2, 3])\n",
    "print(x)\n",
    "\n",
    "# 创建一个全一Tensor\n",
    "x = torch.ones([2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f354fd4",
   "metadata": {},
   "source": [
    "1.2. Tensor的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8070a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 7, 7],\n",
      "        [7, 7, 7]])\n",
      "tensor([[-5, -3, -1],\n",
      "        [ 1,  3,  5]])\n",
      "tensor([[ 6, 10, 12],\n",
      "        [12, 10,  6]])\n",
      "tensor([[ 6, 10, 12],\n",
      "        [12, 10,  6]])\n",
      "tensor([[28, 10],\n",
      "        [73, 28]])\n",
      "tensor([[28, 10],\n",
      "        [73, 28]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [6, 5, 4],\n",
      "        [3, 2, 1]])\n",
      "tensor([[1, 2, 3, 6, 5, 4],\n",
      "        [4, 5, 6, 3, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 加减法\n",
    "x = torch.tensor([[1,2,3],\n",
    "                  [4,5,6]])\n",
    "y = torch.tensor([[6,5,4],\n",
    "                  [3,2,1]])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "\n",
    "# 对应位置相乘\n",
    "print(x * y)\n",
    "print(x.mul(y))\n",
    "\n",
    "# 矩阵乘法\n",
    "print(x.matmul(y.T))\n",
    "print(x @ y.T)\n",
    "\n",
    "# reshape\n",
    "print(x.reshape(3, 2))\n",
    "\n",
    "# 拼接\n",
    "print(torch.cat([x,y], dim=0)) # 纵向拼接\n",
    "print(torch.cat([x,y], dim=1)) # 横向拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95961cee",
   "metadata": {},
   "source": [
    "1.3. Tensor与ndarray的相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1269212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[0 0 0]\n",
      " [0 0 0]]\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "\n",
    "# 从Tensor转换到ndarray\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "\n",
    "# Tensor与ndarray是共享空间的\n",
    "x[:]=0\n",
    "print(y)\n",
    "\n",
    "# 从ndarray到Tensor\n",
    "z = torch.from_numpy(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c36a7",
   "metadata": {},
   "source": [
    "**<font color = green size=3>2.梯度计算</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3f1a6",
   "metadata": {},
   "source": [
    "2.1 梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9113eb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.]])\n",
      "None\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#定义变量\n",
    "a = torch.tensor([[1., 2.]], requires_grad=True)\n",
    "b = torch.tensor([[3.], [4.]])\n",
    "c = torch.tensor(5., requires_grad=True)\n",
    "\n",
    "#计算输出\n",
    "z = a @ b + c\n",
    "\n",
    "#自动计算梯度\n",
    "z.backward()\n",
    "\n",
    "#输出叶子节点的梯度\n",
    "print(a.grad) #z对a的梯度\n",
    "print(b.grad) #由于b默认requires_grad为false，因此无法计算梯度，输出为None\n",
    "print(c.grad) #z对c的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a046cd",
   "metadata": {},
   "source": [
    "2.2 梯度清零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04cda9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "梯度（a.grad）: tensor([0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966,\n",
      "        0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966, 0.1966,\n",
      "        0.1966, 0.1966])\n",
      "求梯度后的结果（x.grad）: tensor(4.)\n",
      "求梯度后的结果（x.grad）: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#支持多种运算求梯度，如torch.mean(),torch.sum()等\n",
    "a = torch.ones(20, requires_grad=True)\n",
    "z = torch.sum(torch.sigmoid(a))\n",
    "z.backward()\n",
    "print(\"梯度（a.grad）:\", a.grad)\n",
    "\n",
    "\n",
    "#多次求梯度时梯度会累加，可使用tensor.grad.zero_()进行手动清零\n",
    "x = torch.tensor(2., requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(\"求梯度后的结果（x.grad）:\", x.grad)\n",
    "\n",
    "z = x + 3\n",
    "x.grad.zero_()  #可以将这句进行手动清零的代码注释掉后查看输出结果，来看到梯度清零的作用\n",
    "z.backward()\n",
    "print(\"求梯度后的结果（x.grad）:\", x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d22808",
   "metadata": {},
   "source": [
    "**<font color = green size=3>3. 神经网络</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2064274",
   "metadata": {},
   "source": [
    "3.1 神经网络的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "207b6433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义神经网络模型，继承自nn.Module\n",
    "class Net(nn.Module):\n",
    "    #输入层的维度为 input_dim\n",
    "    #隐藏层的维度为 hidden_dim\n",
    "    #输出层的维度为 output_dim\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        #激活函数relu，用于在全连接层之间加入非线性变换\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out1 = self.relu(out)\n",
    "        out2 = self.fc2(out1)\n",
    "        return out1,out2\n",
    "\n",
    "\n",
    "# 创建神经网络模型实例并输出\n",
    "net = Net(10,5,1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91efbf82",
   "metadata": {},
   "source": [
    "3.2 神经网络参数查询"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c2a943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([5, 10]), torch.Size([5]), torch.Size([1, 5]), torch.Size([1])]\n",
      "Parameters: [Parameter containing:\n",
      "tensor([[-1.0985e-01, -7.6312e-02, -2.0128e-01, -1.1968e-02, -2.6385e-01,\n",
      "          2.5134e-01,  1.8929e-01,  1.4129e-01,  5.4100e-02,  2.4919e-01],\n",
      "        [-1.6939e-01,  3.0797e-03,  1.2730e-01, -2.8699e-01,  6.4637e-02,\n",
      "          1.6762e-01, -3.6328e-02,  3.0643e-01, -2.8438e-01, -2.4651e-01],\n",
      "        [-7.0283e-02,  3.1723e-02, -8.8639e-02, -2.5455e-01,  2.6949e-01,\n",
      "         -1.3448e-01,  1.1654e-01,  2.2735e-01, -2.1453e-01,  2.8511e-01],\n",
      "        [ 4.0381e-02, -2.4621e-01, -3.1451e-01,  1.6439e-01,  2.6017e-01,\n",
      "          1.4010e-01,  7.0870e-05,  2.5389e-01, -1.5460e-01,  8.2921e-02],\n",
      "        [ 1.4023e-01,  1.8721e-01, -7.6787e-02, -3.3322e-02, -2.2830e-01,\n",
      "         -1.8822e-01, -2.1006e-01,  1.5386e-01, -2.8845e-01, -2.5285e-01]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0196,  0.1281, -0.0757,  0.1749, -0.0495], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0953, -0.4201,  0.2050,  0.3530, -0.1766]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3938], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# 该神经网络中可学习的参数可以通过net.parameters()访问\n",
    "params = list(net.parameters())\n",
    "print([params[i].size() for i in range(len(params))])  \n",
    "print(\"Parameters:\",params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d5c67",
   "metadata": {},
   "source": [
    "3.3 神经网络前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b733263e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of first layer: tensor([[0.4005, 0.0000, 0.2670, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "Output of second layer: tensor([[-0.2747]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "#输入维度为10，生成数据\n",
    "input=torch.ones([1,10])\n",
    "input=input.float()\n",
    "\n",
    "# 进行一次forward()前向传播\n",
    "output1, output2  = net(input) \n",
    "\n",
    "# 前向传播并输出每一层的输出值\n",
    "print(\"Output of first layer:\", output1)\n",
    "print(\"Output of second layer:\", output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89909999",
   "metadata": {},
   "source": [
    "3.4 神经网络反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c8f10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients of first layer:\n",
      "tensor([[-0.1460, -0.1460, -0.1460, -0.1460, -0.1460, -0.1460, -0.1460, -0.1460,\n",
      "         -0.1460, -0.1460],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.1637,  0.1637,  0.1637,  0.1637,  0.1637,  0.1637,  0.1637,  0.1637,\n",
      "          0.1637,  0.1637],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]])\n",
      "tensor([-0.1460,  0.0000,  0.1637,  0.0000,  0.0000])\n",
      "Gradients of second layer:\n",
      "tensor([[0.3021, 0.0000, 0.2014, 0.0000, 0.0000]])\n",
      "tensor([0.7542])\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "target = torch.randn(1, 1)\n",
    "loss = loss_fn(output2, target)\n",
    "\n",
    "# 反向传播并输出每一层的梯度\n",
    "net.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "print(\"Gradients of first layer:\")\n",
    "print(net.fc1.weight.grad)\n",
    "print(net.fc1.bias.grad)\n",
    "\n",
    "print(\"Gradients of second layer:\")\n",
    "print(net.fc2.weight.grad)\n",
    "print(net.fc2.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9fb6e",
   "metadata": {},
   "source": [
    "3.5 训练神经网络的全过程例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4126d755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.3990]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0202], requires_grad=True)]\n",
      "Epoch [1/10], Loss: 11.833146095275879 . Gradient: tensor([[-14.8622]])\n",
      "Epoch [2/10], Loss: 9.364291191101074 . Gradient: tensor([[-13.2205]])\n",
      "Epoch [3/10], Loss: 7.412741184234619 . Gradient: tensor([[-11.7609]])\n",
      "Epoch [4/10], Loss: 5.870094299316406 . Gradient: tensor([[-10.4632]])\n",
      "Epoch [5/10], Loss: 4.650662422180176 . Gradient: tensor([[-9.3094]])\n",
      "Epoch [6/10], Loss: 3.686716079711914 . Gradient: tensor([[-8.2837]])\n",
      "Epoch [7/10], Loss: 2.9247169494628906 . Gradient: tensor([[-7.3716]])\n",
      "Epoch [8/10], Loss: 2.322347402572632 . Gradient: tensor([[-6.5608]])\n",
      "Epoch [9/10], Loss: 1.8461552858352661 . Gradient: tensor([[-5.8398]])\n",
      "Epoch [10/10], Loss: 1.4697006940841675 . Gradient: tensor([[-5.1989]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个简单的线性回归模型\n",
    "model = nn.Linear(1, 1)\n",
    "print(list(model.parameters()))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "Epoch=10\n",
    "\n",
    "#生成数据\n",
    "inputs = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "labels = torch.tensor([[2.0], [4.0], [6.0]])\n",
    "\n",
    "# 模拟训练过程\n",
    "for epoch in range(Epoch):\n",
    "    # 模拟输入数据和标签\n",
    "    \n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    #梯度清零\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "\n",
    "    \n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "\n",
    "    # 打印梯度值\n",
    "    print('Epoch [{}/{}], Loss: {}'.format(epoch+1,Epoch, loss),'. Gradient: {}'.format(model.weight.grad))\n",
    "    #print('Gradient: {}'.format(model.weight.grad))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d39b00",
   "metadata": {},
   "source": [
    "3.5 神经网络参数更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f54bd7",
   "metadata": {},
   "source": [
    "1) 用梯度下降法(手动)更新net中的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7187507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for f in net.parameters():\n",
    "    #f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee49df5",
   "metadata": {},
   "source": [
    "2) 用PyTorch的优化器来更新net中的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "06d237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#选择优化器\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 建立循环:\n",
    "#optimizer.zero_grad()             # 梯度清零\n",
    "#output = net(input)               # 前向传播\n",
    "#loss = criterion(output, target)  # 计算误差\n",
    "#loss.backward()                   # 后向传播\n",
    "#optimizer.step()                  # 参数更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be2d1f",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第二部分:实验内容</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5214e5",
   "metadata": {},
   "source": [
    "[Red Wine Quality](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)是一个关于红酒品质的数据集，总共有1599个样本，每个样本包含11个(都是连续的)特征以及1个标签，每个标签的取值是连续的。本次实验已经按照8：2的比例划分成了训练数据集'wine_train.csv'以及测试数据集'wine_test.csv'，且每个数据集都已经做了归一化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9ccac",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">1) 读入训练数据集'wine_train.csv'与测试数据集'wine_test.csv'。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c759660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 12)\n",
      "(320, 12)\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "wine_train = pd.read_csv(\"wine_train.csv\")\n",
    "wine_test = pd.read_csv(\"wine_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77619fd",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">2) 利用线性层和激活函数搭建一个神经网络，要求输入和输出维度与数据集维度一致，而神经网络深度、隐藏层大小、激活函数种类等超参数自行调整。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26359bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = wine_train.shape[1] - 1\n",
    "hidden_dim = 5\n",
    "output_dim = 1\n",
    "# print(input_dim)\n",
    "\n",
    "\n",
    "# 定义神经网络模型，继承自nn.Module\n",
    "class Net(nn.Module):\n",
    "    # 输入层的维度为 input_dim\n",
    "    # 隐藏层的维度为 hidden_dim\n",
    "    # 输出层的维度为 output_dim\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        # 激活函数relu，用于在全连接层之间加入非线性变换\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out1 = self.relu(out)\n",
    "        out2 = self.fc2(out1)\n",
    "        return out1, out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b706eea",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">3) 用PyTorch的优化器(随机梯度下降)来进行模型参数更新，记下每轮迭代中的训练损失和测试损失。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad2f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ff45e",
   "metadata": {},
   "source": [
    "<span style=\"color:purple\">4) 画出训练损失和测试损失关于迭代轮数的折线图。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba3071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaceea0",
   "metadata": {},
   "source": [
    "**<font color = blue size=4>第三部分:作业提交</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564e8a6",
   "metadata": {},
   "source": [
    "一、实验课下课前提交完成代码，如果下课前未完成，请将已经完成的部分进行提交，未完成的部分于之后的实验报告中进行补充  \n",
    "要求:  \n",
    "1)文件格式为：学号-姓名.ipynb  \n",
    "2)【不要】提交文件夹、压缩包、数据集等无关文件，只需提交单个ipynb文件即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af5b08",
   "metadata": {},
   "source": [
    "二、本次实验分为两周完成，实验报告提交截止日期: 12月15号14:20  \n",
    "要求：  \n",
    "1)文件格式为：学号-姓名.pdf  \n",
    "2)【不要】提交文件夹、压缩包、代码文件、数据集等任何与实验报告无关的文件，只需要提交单个pdf文件即可  \n",
    "3)文件命名时不需要额外添加“实验几”等额外信息，按照格式提交  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e73e3",
   "metadata": {},
   "source": [
    "实验十二(神经网络)的实验报告上交地址: https://send2me.cn/Wk9FsyYO/SKCBsWeFtvwQsg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db7ee4",
   "metadata": {},
   "source": [
    "三、课堂课件获取地址:https://www.jianguoyun.com/p/DWHYtsEQp5WhChjwtKoFIAA\n",
    "实验内容获取地址:https://www.jianguoyun.com/p/DbNY_SIQp5WhChjvtKoFIAA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
