Flappy游戏中的状态S包括小鸟的位置、障碍物的位置以及小鸟是否存活，动作A包括飞与不飞。

创建Q值表，存储每个状态动作对的Q值。Q(s,a)就是在某一时刻的s状态下(s∈S)，采取动作a (a∈A)动作能够获得收益的期望，环境会根据agent的动作反馈相应的回报reward。

将Q表的初始值设为0或一个较小的随机值。

然后开始迭代

1. 引入ε-greedy策略。以ε的概率随机选择一个动作，以1-ε的概率选择具有最大Q值的动作。
2. 执行动作，观察环境的反馈（奖励或惩罚），根据Q-learning的更新规则，更行Q表中的Q值以反映当前状态和动作的预期回报。

重复1和2过程，直到小鸟死亡。
